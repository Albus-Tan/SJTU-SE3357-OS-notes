[TOC]

# 虚拟内存

如何让OS与不同的应用程序（多用户多程序）都高效又安全地使用物理内存资源？

分时复用物理内存资源的话，切换时将全部内存写入磁盘开销太高；同时使用，各占一部分物理内存的话缺乏安全性和隔离性。

- IBM 360的内存隔离：Protection Key
  - 物理内存的旁边放了一组寄存器（内存被划分为2KB内存块，每个内存块有一个4-bit的key，保存在寄存器中）
  - 每一个进程也对应一个key，进程只能访问与其key一样的内存块！

**希望让应用看不见物理地址**（应用会因为其他应用的加载而受到影响；一旦物理地址范围确定，很难使用更大范围的内存，扩展性差；安全性上，应用可以通过自身内存地址猜测其他应用的位置）

**优势**

- 高效使用物理内存（资源有限）
- 简化内存管理（每个进程看到的是统一的线性地址空间，不用担心别的进程在干什么）
- 更强的隔离性和更细粒度的权限控制

## 虚拟地址

- 地址翻译（物理地址可以不连续，但是在虚拟地址中可以体现为连续）
- 支持隔离（不同进程虚拟地址空间不同）

## 虚拟内存的组织：分段与分页

### 分段

<img src="vm-manage 虚拟内存管理.assets/image-20230228111039689.png" alt="image-20230228111039689" style="zoom:50%;" />

- 翻译时一个虚拟地址（段内地址）需要加上起始地址（根据段号找到）得到物理地址
- 每个进程都可包含代码段、数据段等，与进程自身的内存布局相匹配

**分段机制问题**

- 本段长度有限制
- 对物理内存有连续性要求（如堆和栈），需要预留空间
  - 内存利用率低（外部和内部碎片）

### 分页

<img src="vm-manage 虚拟内存管理.assets/image-20230228111345492.png" alt="image-20230228111345492" style="zoom:50%;" />

粒度恒定的分段机制

- 页表包含多个页表项，存储物理页的页号（虚拟页号为索引）
- 物理内存离散分配，大大降低对物理内存的连续性要求，减少碎片

## ARM64 的页表格式

### 多级页表

- 有效压缩页表的大小
- 允许页表中出现空洞（某级页表中的某条目为空，那么该条目对应的下一级页表无需存在；应用程序的虚拟地址空间大部分都未分配）

**多级页表什么时候不如单级页表**

占满的时候。前面几级页表都浪费了，并且查找的时候很慢。

### AARCH64 体系结构下4级页表

<img src="vm-manage 虚拟内存管理.assets/AARCH64-page-table.jpg" alt="AARCH64-page-table" style="zoom: 67%;" />

### 虚拟地址解析

<img src="vm-manage 虚拟内存管理.assets/image-20230301105014143.png" alt="image-20230301105014143" style="zoom: 33%;" />

### 页表基地址寄存器

<img src="vm-manage 虚拟内存管理.assets/image-20230301105104581.png" alt="image-20230301105104581" style="zoom: 33%;" />

<img src="vm-manage 虚拟内存管理.assets/image-20230301105309563.png" alt="image-20230301105309563" style="zoom:50%;" />

### Level 3 页表项

<img src="vm-manage 虚拟内存管理.assets/image-20230301105411860.png" alt="image-20230301105411860" style="zoom: 33%;" />

<img src="vm-manage 虚拟内存管理.assets/image-20230301105448177.png" alt="image-20230301105448177" style="zoom:33%;" />

<img src="vm-manage 虚拟内存管理.assets/image-20230301105511234.png" alt="image-20230301105511234" style="zoom:33%;" />

### Level 0，Level 1，Level 2 页表项

<img src="vm-manage 虚拟内存管理.assets/image-20230301105611642.png" alt="image-20230301105611642" style="zoom:33%;" />

<img src="vm-manage 虚拟内存管理.assets/image-20230303082110238.png" alt="image-20230303082110238" style="zoom: 33%;" />

**什么时候应该用大页？**

大数据的场景，更少的TLB miss

## TLB：地址翻译的加速器，页表的cache（不是页表页传统数据通路走的那个内存的cache）

- TLB位于CPU内部，是**页表的缓存**
  - Translation Lookaside Buffer
  - 缓存了虚拟页号到物理页号的映射关系
  - **有限数目**的TLB缓存项

- 在地址翻译过程中，MMU首先查询TLB
  - TLB命中，则不再查询页表 （**fast** **path**）
  - TLB未命中，再查询页表

TLB一个一个查，非常慢

TLB难以再提升性能！随着内存越来越大（页表也随之变大），出现与内存不match的情况（两者性能变大斜率不一致！）

### TLB清空：TLB Flush

切换进程（虚拟地址空间变化，页表也会相应换掉）的时候就要清空TLB；在现有知识体系下，内核和用户态之间发生切换不需要清空TLB（内核和应用程序在同一个地址空间里面，地址空间没有发生变化）

- TLB 使用虚拟地址索引
  - 当OS切换页表时需要全部刷掉
- AARCH64上内核和应用程序使用不同的页表
  - 分别存在TTBR0_EL1和TTBR1_EL1
  - 系统调用过程不用切换
- x86_64上只有唯一的基地址寄存器
  - 内核映射到应用页表的高地址
  - 避免系统调用时TLB清空的开销

#### 降低TLB清空导致的开销

- 新的硬件特性ASID（Address Space ID）：OS为不同进程分配8或16位的ASID，将其填写在TTBR0_EL1的高位。TLB每一项头上也加上ASID。在切换进程的时候就不需要清空TLB（同一个虚拟地址不同进程，ASID不一样；使用TLB条目时候检查ASID是否匹配）
  - 缺点：如果有8位，只能256个进程

> **注意：TLB是页表映射的cache，和页表内存页的cache（通常说的缓存）完全不一样！！！**

**OS修改页表后，需要刷掉其它核的TLB吗？**

如果别的核和当前核跑的同一个进程的不同线程（并且属于这个页表），要刷

**OS如何知道需要刷掉哪些核的TLB？**

操作系统要知道进程调度信息（当前改的页表属于哪个进程，看看别的核有没有跑这个进程）

**OS如何刷掉其它核的TLB？**

- x86_64: 发送IPI（CPU核向别的CPU核发出的中断）中断某个核，通知它主动清空

- AARCH64: 可在local CPU上清空其它核TLB
  - 调用的ARM指令：TLBI ASIDE1IS

**内存和CPU一定是CPU缓存中的数据更新吗（内存比CPU的数据更新的模式）？**

- 磁盘（外设）直接修改内存（如DMA，磁盘直接访问DRAM），此时就不经过CPU（CPU对此磁盘改了内存不知情），内存的cache（在CPU中）就失效了
- DMA对应的memory应当设置为non-cacheable，也即不让其被缓存！显然这会导致频繁读写时性能不高（因为没有cache导致），可以通过将这块non-cacheable的内存拷贝到cacheable的内存部分（不会多出拷贝的操作，因为总之需要进行copy to user，应用程序用这块内存不可能访存到在OS中的地址空间）来解决

- DMA在OS中通常是特定的一块内存（比cache更新）；DMA常常用作和IO设备交互的memory




## 虚拟内存：段和VMA

**应用程序有自己独立的虚拟地址空间，那直接拿指针一点一点遍历自己的地址空间，可以做到吗？**

不能。虽然是自己的虚拟地址空间，但并不是应用程序都能直接用，会存在空洞！！！除了代码段和栈等，其它必须要先malloc声明某一段虚拟地址区域自己要用，才能访问。

- OS采用**段**来管理虚拟地址
  - 段内连续，段与段之间非连续
  - 合法虚拟地址段：代码、（只读）数据、堆、栈
  - 非法虚拟地址段：未映射（一旦访问，则触发segfault）

**为什么要使用段来管理？**

因为段的数量比页要少很多，通常每一段都有相同的属性，比如只读、可执行等等，可简化管理

**malloc的时候不会真的分配物理地址！只有VMA发生变化；页表不会发生变化**

### <u>VMA：合法虚拟地址信息的记录方式</u>（OS记录应用程序已分配的虚拟内存端）

- 记录应用程序已分配的虚拟内存区域
  - 在Linux中对应 vm_area_struct（VMA）结构体

<img src="vm-manage 虚拟内存管理.assets/image-20230302103006448.png" alt="image-20230302103006448" style="zoom: 33%;" />

#### VMA是如何添加的

- 途径1: OS在创建应用程序时分配（数据（对应ELF段），代码（对应ELF段），栈（初始无内容））
- 途径2: 应用程序主动向OS发出请求
  - `brk()`（扩大、缩小**堆**区域）：可选策略，OS也可以在创建应用时分配初始的堆VMA；**并不是让OS给堆分配更多的物理内存资源！只是虚拟内存地址空间**
  - `mmap()` ：申请一段空的虚拟内存区域，申请映射文件数据的虚拟内存区域（把文件整体映射到内存的某个区域，这样读这个文件就不需要read，write这样的syscall，而直接像访问内存一样访问这个文件即可；匿名映射即指不需要这样一个文件的存在，也可以做这种映射）

- 用户态的malloc会改变VMA
  - 通常是调用brk，在堆中分配新的内存
  - 部分实现也可以调用mmap，由应用管理多个VMA

#### mmap：分配一段虚拟内存区域

<img src="vm-manage 虚拟内存管理.assets/image-20230302163801207.png" alt="image-20230302163801207" style="zoom: 25%;" />

<img src="vm-manage 虚拟内存管理.assets/image-20230302163924220.png" alt="image-20230302163924220" style="zoom:25%;" />

该操作并**没有做任何物理内存的分配**！！整个系统里唯一变化的是VMA。访问该新区域会出发page fault，并填充页表。

**VMA和页表是否冗余？**

不冗余。VMA记录的这块区域不一定有页表映射！（VMA覆盖面更大）。如果用立即映射，VMA和页表覆盖范围一致，此时VMA唯一的作用可能仅仅是快速判断。如果是延迟映射，就很需要！

#### <u>页表填写策略</u>

**操作系统何时为应用程序填写页表？**

- **<u>立即映射</u>**：每个虚拟页都对应了一个物理内存页

- **<u>延迟映射</u>/按需调页（Demand Paging）**：有些虚拟页不对应任何物理内存页

  - 对应的数据在磁盘上

  - 没有对应的数据（初始化为0）（如 `mmap` 凭空映射一块区域）

  - 可以节约内存资源，但是缺页异常会导致访问延迟增加

    - 如何取得平衡？

      应用程序访存具有时空局部性（Locality）

      在缺页异常处理函数中采用预取（Prefetching）机制（猜测locality，多取并初始化一些页）

      即节约内存又能减少缺页异常次数

#### mmap的流程

<img src="vm-manage 虚拟内存管理.assets/image-20230303081051981.png" alt="image-20230303081051981" style="zoom:50%;" />

调用mmap映射文件时，内核中会为mmap的区域创建一个vma，并且将对应标识文件的内核对象V-NODE与这个vma绑定。此时这块区域的页表中并没有对应任何物理页。

<img src="vm-manage 虚拟内存管理.assets/image-20230303081112810.png" alt="image-20230303081112810" style="zoom:50%;" />

当访问这块内存时，会触发 page fault，内核会检查 fault 地址，发现其对应的 vma 绑定了一个 v-node，就会从磁盘读取对应的页内容到页缓存，并将页缓存与用户地址空间的内容映射到同一个物理页。

<img src="vm-manage 虚拟内存管理.assets/image-20230303081129662.png" alt="image-20230303081129662" style="zoom:50%;" />

对于mmap内存区域的写会直接修改页缓存中的内容。

<img src="vm-manage 虚拟内存管理.assets/image-20230303081145188.png" alt="image-20230303081145188" style="zoom:50%;" />

当文件被关闭或调用msync时，页缓存中修改的数据会被刷回磁盘。

- Prefault
  - 每次 page fault 载入连续的多个页，减少 fault 次数
- MAP_POPULATE
  - 通过一个包含 MAP_POPULATE 的 flags 参数，可以在调用 mmap 时就预取所有的页，此后访问不会 fault

#### 缺页异常（Page Fault）

- CPU的控制流转移
  - CPU陷入内核，找到并运行相应的异常处理函数（handler）
  - OS提前注册缺页异常处理函数

- x86_64
  - 异常号 #PF （13），错误地址存放在CR2寄存器

- AARCH64
  - 触发（通用的）同步异常（8）
  - 根据ESR信息判断是否缺页，错误地址存放在FAR_EL1（作用类似于x86中的CR2）

##### 缺页异常的三种可能

1. 访问非法虚拟地址【非法】
2. 按需分配（尚未分配真正的物理页）【合法】
3. 内存页数据被换出到磁盘上【合法】

> 用VMA来区分。第一种，不在VMA区域；第二种和第三种，在VMA区域

> 区分后两种的思路是：
>
> 记住有哪些页被换出，比如hash表可以解决。
>
> 更简单的方法：通过页表项某些位是否为NULL进行区分。（OS自己定义规则：NULL代表非法，非NULL代表swap）

**2与3如何区分？**

在页表项PTE中设一位来表示

**如何判断缺页异常的合法性？**

不落在VMA区域，则为非法



**mmap匿名映射与文件映射的区别是什么？**

匿名映射的背后没有文件

没有backup file，内存的初始值从哪里来？0

**如果OS仅采用立即映射，还需要VMA么？**

VMA记录的信息和页表记录的信息有何不同？

VMA只记录虚拟地址的范围，而页表还记录了和物理地址的映射

**demand-paging是否可通过网络来实现？**

如果都通过网络，本地是否还需要磁盘？

可以通过网络，不需要磁盘，实现无盘工作站（现代网卡可以做到比磁盘快，因而相较于放到本地的磁盘，更愿意放到远端机器的内存中)

**什么时候会修改页表？**

1. 触发page fault的时候（比如demand paging的时候，此时不需要flush TLB，是添加条目）
2. 换页的时候（删除某条目，需要flush TLB）
3. 删除一个进程的时候，页表项都会被删掉

## 虚拟内存的扩展功能

- 共享内存
  - 节约内存，如共享库
  - 进程通信，传递数据
- 写时拷贝（copy-on-write）
  - 实现
    - 修改页表项权限
    - 在缺页时拷贝与恢复
  - 如fork时（可以节约物理内存，并且性能加速）
- 内存去重
  - OS做，对用户态透明
  - 在内存中扫描找相同内容的物理页面，并执行去重合并
  - 同一块内存映射到不同虚拟地址空间
- 内存压缩
  - 内存不足时，将不大使用的内存压缩/放到硬盘中

**什么情况可以不用虚拟内存**

- 物理内存足够多，远远大于应用程序需求（没必要再有这些额外的开销）
- 在目前的64位地址下，其实可以做到随便分配，为每一个应用程序分足够大的地址空间，并且不重叠
- 如果只用物理内存，不适合多用户，适合单用户

**如果不依靠 MMU，是否有可以替换虚拟内存的方法？**

- 基于高级语言实现多个同一个地址空间内运行实例的隔离

- 基于编译器插桩实现多个运行实例的隔离（访问的时候检查，是不是分配给自己的地址空间）